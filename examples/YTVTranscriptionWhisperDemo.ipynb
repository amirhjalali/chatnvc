{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirhjalali/chatnvc/blob/main/examples/YTVTranscriptionWhisperDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRB4prIxFQvD",
        "outputId": "5ee3e364-97fc-4c52-9242-bed8eb2be759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1THkEoXiFGqC"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxVAiYThFGqE"
      },
      "outputs": [],
      "source": [
        "link='https://www.youtube.com/watch?v=dT_aIJZ7Mxw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgzjYcmBFGqE"
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    # object creation using YouTube\n",
        "    # which was imported in the beginning \n",
        "    yt = YouTube(link) \n",
        "except: \n",
        "    print(\"Connection Error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibA2bGLuFGqF",
        "outputId": "6c7eaa5a-0a2e-45a3-dd93-e1ecf7533d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        " yt.streams.filter(file_extension='mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mj3iS5eFGqF"
      },
      "outputs": [],
      "source": [
        "stream = yt.streams.get_by_itag(139)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBbeebEZFGqG",
        "outputId": "4033bf77-e9b7-408c-c7fa-0d9e9080898a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GoogleImagen.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "stream.download('',\"GoogleImagen.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXSgQWQJwX0",
        "outputId": "08bc5da9-31b0-4005-f7fe-1a13c6a6ad32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-upe9lddr\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-upe9lddr\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (8.14.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 28.0 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 67.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers>=4.19.0->whisper==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175020 sha256=397bee2c2ef36f25364b0e894b5269dc6ae717f3db255aa34313c2f4fa122895\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p225m_ag/wheels/16/15/89/1c7bb31bd0006793a95549d04785121a8a36daad9158e1e43a\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2 whisper-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 42.7 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 48.9 MB/s \n",
            "\u001b[?25hCollecting jarowinkler<2.0.0,>=1.2.2\n",
            "  Downloading jarowinkler-1.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 69.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: jarowinkler, rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jarowinkler-1.2.3 jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"GoogleImagen.mp4\")\n",
        "print(result['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJwhMsOhJgQm",
        "outputId": "24a1f72e-1978-45b4-c66a-0e15123bd4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 135MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " In this video, let's look at image and a new AI system from Google Brain. So what does image and image and text as an input and then generates images. For example, the text over here is a chrome plated duck with a golden beak arguing with an angry turtle in a forest. So this is the text given and this is the image generated. So how does this system work? So this system takes text as an input. There is a frozen text encoder which produces a text embedding. This text embedding is then fed into a series of image diffusion models. There is a first text to image diffusion model which generates an image. Then there is a super resolution diffusion model which is used for increasing the resolution. Then you have another super resolution diffusion model which gives you the final image. And each of these diffusion models takes the text embedding as the input along with the previous output of the previous stage. So for the text encoder over here, they use a T5-XXL encoder to encode the input text into embeddings. Then they have conditional diffusion model maps that text embedding into the various 64 into 64 image. Then there is a further super-convict text condition, super resolution diffusion model which can upsample the image. 64 image into the final image. And if you look at the photos over here which have been generated based on the captions, the photo quality and the photo realism is much high when compared to Dali. Here is another example which they show over here. You can click on a word and you can see what is the kind of image which has been generated. For example, a photo of a British short hair cat wearing a cowboy hat and a red shirt riding a bike on a beach. This is the kind of image you get. If you go to the other one, this is an oil painting of the same thing. For example, this is a Persian cat. This is the image which has been generated. If you click on Fuzzy Panta, for the panda, this is the kind of image which has been generated based on this highlighted text caption. This is playing a guitar, this is riding a bike, this is skate boarding on top of a mountain. This is an oil painting. If you go to photo, you see this photo quality which has been generated. This seems much better than Dali and they say that when they looked at the benchmarks over here, they have attained a new state of art score. Image fidelity score when compared to Dali or the other models on the cocoa dataset. This is quite interesting work and I am amazed at the pace at which AI is developing now with newer models being developed by these big, big research teams achieving newer, fascinating results. I hope you liked this video on Image and if you liked the video, please like share subscribe to the channel, see you in another video. Happy learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EFtEStD6MGQZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
